{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "\n",
    "Final version is used as on Constance:\n",
    "    \n",
    "/pic/projects/hyperion/chen423/tools/paper_tools/AR-SST/step4.extract_ARstats.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/home/chen423/.tmp/AR-SST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crt_filenames(model, year, month):\n",
    "    \n",
    "    WRFdir = rootdir + '%s/WRF_IWV_uvIVT/' % model\n",
    "    WRFfile = WRFdir + 'WRF_IWV_uvIVT.6hr.%d.%d.nc' % (year, month)\n",
    "    \n",
    "    return WRFfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AR_intensity_data(model, year, month):\n",
    "    \n",
    "    WRFfile = crt_filenames(model, year, month)\n",
    "    \n",
    "    WRF_IVT = xr.open_dataset(WRFfile).uvIVT.values\n",
    "    WRF_IWV = xr.open_dataset(WRFfile).IWV.values\n",
    "    \n",
    "    return WRF_IVT, WRF_IWV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARp85_s100_state1_post1_c1000\n"
     ]
    }
   ],
   "source": [
    "ARtag = 'p85'\n",
    "flag_area = 100   # minimum size of patches (over land and over ocean, both)\n",
    "flag_USstate = 1  # whether to use US west coast 5 states along with land mask. 1 is to use, 0 is to skip\n",
    "flag_post_adj = 1  # WRF further adjusted, or not (i.e., directly from modified NARR). 1 is further adjusted, 0 for raw\n",
    "\n",
    "commonAR_thre = 1000\n",
    "\n",
    "version_tag = 'AR%s_s%d_state%d_post%d_c%d' % (ARtag, flag_area, flag_USstate, flag_post_adj, commonAR_thre)\n",
    "print(version_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### major AR-related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_6hrly_AR_SST(in_ARtag, in_SST):\n",
    "    ocean_AR_union = (ocean_mask==1)*(in_ARtag==1)\n",
    "    out_SSTmean = in_SST[ocean_AR_union==1].mean()\n",
    "    \n",
    "    return out_SSTmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_6hrly_AR_intensity(in_ARtag, in_intensity):\n",
    "    land_AR_union = (ocean_mask==0)*(in_ARtag==1)\n",
    "    out_intensity = in_intensity[land_AR_union==1].mean()\n",
    "    out_totalintensity = in_intensity[land_AR_union==1].sum()\n",
    "    \n",
    "    return out_intensity, out_totalintensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_6hrly_AR_intrusion(in_ARtag):\n",
    "    out_dist_max = (dist_to_coast[in_ARtag==1]).max()\n",
    "    \n",
    "    return out_dist_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AR_stats_separateAR(year, month, ARtag='p85', flag_area=-9999, flag_USstate=-9999, flag_post_adj=-9999):\n",
    "    if flag_post_adj==1:\n",
    "        file_ARHIST = rootdir + 'HIST/AR_tagged/Gershunov/SERDP6km_adj/WRF_ARtag_adj.HIST.Gershunov.%d.%d.AR%s.nc' % (year, month, ARtag)\n",
    "        file_ARfSST = rootdir + 'fSST/AR_tagged/Gershunov/SERDP6km_adj/WRF_ARtag_adj.fSST.Gershunov.%d.%d.AR%s.nc' % (year, month, ARtag)\n",
    "    elif flag_post_adj==0:\n",
    "        file_ARHIST = rootdir + 'HIST/AR_tagged/Gershunov/SERDP6km/WRF_ARtag.HIST.Gershunov.%d.%d.AR%s.nc' % (year, month, ARtag)\n",
    "        file_ARfSST = rootdir + 'fSST/AR_tagged/Gershunov/SERDP6km/WRF_ARtag.fSST.Gershunov.%d.%d.AR%s.nc' % (year, month, ARtag)\n",
    "    \n",
    "    \n",
    "    file_SSTHIST = rootdir + 'HIST/SST/NARR_TS.SERDP6km.6hourly.%d.%d.nc' % (year, month)\n",
    "    \n",
    "    file_SSTfix = rootdir + 'HIST/SST/NARR_TS.SERDP6km.2000.10.01.00.nc'\n",
    "    \n",
    "    \n",
    "    ARtag_HIST = xr.open_dataset(file_ARHIST).AR_tag.values\n",
    "    SST_HIST = xr.open_dataset(file_SSTHIST).var11.values\n",
    "    IVT_HIST, IWV_HIST = get_AR_intensity_data('HIST', year, month)\n",
    "\n",
    "    ARtag_fSST = xr.open_dataset(file_ARfSST).AR_tag.values\n",
    "    SST_fSST = xr.open_dataset(file_SSTfix).var11.values[0]\n",
    "    IVT_fSST, IWV_fSST = get_AR_intensity_data('fSST', year, month)\n",
    "\n",
    "    \n",
    "    # compute various stats\n",
    "    nt = ARtag_HIST.shape[0]\n",
    "    stat_AR_SSTmean = np.zeros((2,nt))-9999\n",
    "    stat_AR_dist = np.zeros((2,nt))-9999\n",
    "    stat_AR_landarea = np.zeros((2,nt))-9999\n",
    "    stat_AR_IVT = np.zeros((2,nt))-9999\n",
    "    stat_AR_IVTs = np.zeros((2,nt))-9999\n",
    "    stat_AR_IWV = np.zeros((2,nt))-9999\n",
    "    stat_AR_IWVs = np.zeros((2,nt))-9999\n",
    "    valid_index = np.zeros((2,nt))\n",
    "    common_AR = np.zeros(nt)\n",
    "\n",
    "    for t in np.arange(nt):\n",
    "        if flag_USstate==1:\n",
    "            sig1 = ((ARtag_HIST[t]==1)*(ocean_mask==0)*(USstate==0)).sum() # land\n",
    "            sig3 = ((ARtag_fSST[t]==1)*(ocean_mask==0)*(USstate==0)).sum() # land\n",
    "        elif flag_USstate==0:\n",
    "            sig1 = ((ARtag_HIST[t]==1)*(ocean_mask==0)).sum() # land\n",
    "            sig3 = ((ARtag_fSST[t]==1)*(ocean_mask==0)).sum() # land\n",
    "        sig2 = ((ARtag_HIST[t]==1)*(ocean_mask==1)).sum()  # ocean\n",
    "        sig4 = ((ARtag_fSST[t]==1)*(ocean_mask==1)).sum() # ocean\n",
    "        sig5 = (ARtag_HIST[t]*ARtag_fSST[t]*(ocean_mask==1)).sum()\n",
    "        #print(t, sig1, sig2, sig3, sig4)\n",
    "        if sig1>flag_area and sig2>flag_area:\n",
    "            valid_index[0,t] = 1\n",
    "            stat_AR_SSTmean[0,t] = compute_6hrly_AR_SST(ARtag_HIST[t], SST_HIST[t])\n",
    "            stat_AR_dist[0,t] = compute_6hrly_AR_intrusion(ARtag_HIST[t])\n",
    "            stat_AR_landarea[0,t] = sig1\n",
    "            stat_AR_IVT[0,t], stat_AR_IVTs[0,t] = compute_6hrly_AR_intensity(ARtag_HIST[t], IVT_HIST[t])\n",
    "            stat_AR_IWV[0,t], stat_AR_IWVs[0,t] = compute_6hrly_AR_intensity(ARtag_HIST[t], IWV_HIST[t])\n",
    "            \n",
    "        if sig3>flag_area and sig4>flag_area:\n",
    "            valid_index[1,t] = 1\n",
    "            stat_AR_SSTmean[1,t] = compute_6hrly_AR_SST(ARtag_fSST[t], SST_fSST)\n",
    "            stat_AR_dist[1,t] = compute_6hrly_AR_intrusion(ARtag_fSST[t])\n",
    "            stat_AR_landarea[1,t] = sig3\n",
    "            stat_AR_IVT[1,t], stat_AR_IVTs[1,t] = compute_6hrly_AR_intensity(ARtag_fSST[t], IVT_fSST[t])\n",
    "            stat_AR_IWV[1,t], stat_AR_IWVs[1,t] = compute_6hrly_AR_intensity(ARtag_fSST[t], IWV_fSST[t])\n",
    "            \n",
    "        if sig1>flag_area and sig2>flag_area and sig3>flag_area and sig4>flag_area and sig5>commonAR_thre:\n",
    "            common_AR[t] = 1\n",
    "            \n",
    "    return stat_AR_SSTmean, stat_AR_dist, stat_AR_landarea, stat_AR_IVT, stat_AR_IVTs, stat_AR_IWV, stat_AR_IWVs, valid_index, common_AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reffile = '/raid1/chen423/serdp/data/ref_data/wrf_ref/SERDP6km.dist_to_coastal.nc'\n",
    "dist_to_coast = xr.open_dataset(reffile).dist_to_coast.values\n",
    "dist_to_coast[dist_to_coast==9999] = 0\n",
    "ocean_mask = np.zeros((450,450))\n",
    "ocean_mask[dist_to_coast==0] = 1\n",
    "\n",
    "\n",
    "reffile = '/raid1/chen423/serdp/data/ref_data/wrf_ref/US_state.nc'\n",
    "USstate = 1-xr.open_dataset(reffile).state_mask.values[0:5].sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. AR information from HIST and fSST\n",
    "\n",
    "They are separately tagged in valid_index, so finding the common ones are not hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 generate the save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on  2003\n",
      "working on  2004\n",
      "working on  2005\n",
      "working on  2006\n",
      "working on  2007\n",
      "working on  2008\n",
      "working on  2009\n",
      "working on  2010\n",
      "working on  2011\n",
      "working on  2012\n",
      "working on  2013\n",
      "working on  2014\n",
      "working on  2015\n"
     ]
    }
   ],
   "source": [
    "stats_AR_SSTmean = np.zeros((2,17532))-9999\n",
    "stats_AR_dist = np.zeros((2,17532))-9999\n",
    "stats_AR_landarea = np.zeros((2,17532))-9999\n",
    "stats_AR_IVT = np.zeros((2,17532))-9999 # over land\n",
    "stats_AR_IWV = np.zeros((2,17532))-9999 # over land\n",
    "stats_AR_IVTs = np.zeros((2,17532))-9999 # over land\n",
    "stats_AR_IWVs = np.zeros((2,17532))-9999 # over land\n",
    "bg_year = np.zeros(17532)-9999\n",
    "bg_month = np.zeros(17532)-9999\n",
    "ARday_index = np.zeros((2,17532))-9999\n",
    "commonAR = np.zeros(17532)-9999\n",
    "\n",
    "sindex = -31*4\n",
    "eindex = 0\n",
    "\n",
    "year = 2003\n",
    "print('working on ', year)\n",
    "for month in np.arange(10,13):\n",
    "    tmp_SSTmean, tmp_dist, tmp_landarea, tmp_IVT, tmp_IVTs, tmp_IWV, tmp_IWVs, tmp_vindex, tmp_c = compute_AR_stats_separateAR(year, month,\n",
    "                                                                                                           ARtag=ARtag,\n",
    "                                                                                                           flag_area=flag_area,\n",
    "                                                                                                           flag_USstate=flag_USstate,\n",
    "                                                                                                           flag_post_adj=flag_post_adj)\n",
    "    \n",
    "    sindex = eindex\n",
    "    eindex = eindex + calendar.monthrange(year, month)[1]*4\n",
    "    stats_AR_SSTmean[:, sindex:eindex] = tmp_SSTmean\n",
    "    stats_AR_dist[:, sindex:eindex] = tmp_dist\n",
    "    stats_AR_landarea[:, sindex:eindex] = tmp_landarea\n",
    "    stats_AR_IVT[:, sindex:eindex] = tmp_IVT\n",
    "    stats_AR_IWV[:, sindex:eindex] = tmp_IWV\n",
    "    stats_AR_IVTs[:, sindex:eindex] = tmp_IVTs\n",
    "    stats_AR_IWVs[:, sindex:eindex] = tmp_IWVs\n",
    "    ARday_index[:, sindex:eindex] = tmp_vindex\n",
    "    bg_year[sindex:eindex] = np.ones(tmp_vindex.shape[1])*year\n",
    "    bg_month[sindex:eindex] = np.ones(tmp_vindex.shape[1])*month\n",
    "    commonAR[sindex:eindex] = tmp_c\n",
    "    \n",
    "    \n",
    "for year in np.arange(2004,2015):\n",
    "    print('working on ', year)\n",
    "    for month in np.arange(1,13):\n",
    "        tmp_SSTmean, tmp_dist, tmp_landarea, tmp_IVT, tmp_IVTs, tmp_IWV, tmp_IWVs, tmp_vindex, tmp_c = compute_AR_stats_separateAR(year, month,\n",
    "                                                                                                               ARtag=ARtag,\n",
    "                                                                                                               flag_area=flag_area,\n",
    "                                                                                                               flag_USstate=flag_USstate,\n",
    "                                                                                                               flag_post_adj=flag_post_adj)\n",
    "    \n",
    "        sindex = eindex\n",
    "        eindex = eindex + calendar.monthrange(year, month)[1]*4\n",
    "        stats_AR_SSTmean[:, sindex:eindex] = tmp_SSTmean\n",
    "        stats_AR_dist[:, sindex:eindex] = tmp_dist\n",
    "        stats_AR_landarea[:, sindex:eindex] = tmp_landarea\n",
    "        stats_AR_IVT[:, sindex:eindex] = tmp_IVT\n",
    "        stats_AR_IWV[:, sindex:eindex] = tmp_IWV\n",
    "        stats_AR_IVTs[:, sindex:eindex] = tmp_IVTs\n",
    "        stats_AR_IWVs[:, sindex:eindex] = tmp_IWVs\n",
    "        ARday_index[:, sindex:eindex] = tmp_vindex\n",
    "        bg_year[sindex:eindex] = np.ones(tmp_vindex.shape[1])*year\n",
    "        bg_month[sindex:eindex] = np.ones(tmp_vindex.shape[1])*month\n",
    "        commonAR[sindex:eindex] = tmp_c\n",
    "        \n",
    "year = 2015\n",
    "print('working on ', year)\n",
    "for month in np.arange(1,10):\n",
    "    tmp_SSTmean, tmp_dist, tmp_landarea, tmp_IVT, tmp_IVTs, tmp_IWV, tmp_IWVs, tmp_vindex, tmp_c = compute_AR_stats_separateAR(year, month,\n",
    "                                                                                                           ARtag=ARtag,\n",
    "                                                                                                           flag_area=flag_area,\n",
    "                                                                                                           flag_USstate=flag_USstate,\n",
    "                                                                                                           flag_post_adj=flag_post_adj)\n",
    "    \n",
    "    sindex = eindex\n",
    "    eindex = eindex + calendar.monthrange(year, month)[1]*4\n",
    "    stats_AR_SSTmean[:, sindex:eindex] = tmp_SSTmean\n",
    "    stats_AR_dist[:, sindex:eindex] = tmp_dist\n",
    "    stats_AR_landarea[:, sindex:eindex] = tmp_landarea\n",
    "    stats_AR_IVT[:, sindex:eindex] = tmp_IVT\n",
    "    stats_AR_IWV[:, sindex:eindex] = tmp_IWV\n",
    "    stats_AR_IVTs[:, sindex:eindex] = tmp_IVTs\n",
    "    stats_AR_IWVs[:, sindex:eindex] = tmp_IWVs\n",
    "    ARday_index[:, sindex:eindex] = tmp_vindex\n",
    "    bg_year[sindex:eindex] = np.ones(tmp_vindex.shape[1])*year\n",
    "    bg_month[sindex:eindex] = np.ones(tmp_vindex.shape[1])*month\n",
    "    commonAR[sindex:eindex] = tmp_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile = rootdir + 'intermediate_data/AR_stats_separate.%s.mat' % version_tag\n",
    "sio.savemat(tmpfile, {'stats_AR_SSTmean':stats_AR_SSTmean, 'stats_AR_dist':stats_AR_dist,\n",
    "                      'stats_AR_landarea':stats_AR_landarea, 'stats_AR_IVT':stats_AR_IVT,\n",
    "                      'stats_AR_IVTs':stats_AR_IVTs, 'stats_AR_IWVs':stats_AR_IWVs,\n",
    "                      'stats_AR_IWV':stats_AR_IWV, 'ARday_index':ARday_index,\n",
    "                      'bg_year':bg_year, 'bg_month':bg_month, 'commonAR':commonAR})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. land. AR frac and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpfile = rootdir + 'intermediate_data/AR_stats_separate.%s.mat' % version_tag\n",
    "stats_AR_SSTmean = sio.loadmat(tmpfile)['stats_AR_SSTmean']\n",
    "stats_AR_dist = sio.loadmat(tmpfile)['stats_AR_dist']\n",
    "stats_AR_landarea = sio.loadmat(tmpfile)['stats_AR_landarea']\n",
    "stats_AR_IVT = sio.loadmat(tmpfile)['stats_AR_IVT']\n",
    "stats_AR_IWV = sio.loadmat(tmpfile)['stats_AR_IWV']\n",
    "ARday_index = sio.loadmat(tmpfile)['ARday_index']\n",
    "bg_year = sio.loadmat(tmpfile)['bg_year']\n",
    "bg_month = sio.loadmat(tmpfile)['bg_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AR_maps(model, year, month):\n",
    "    \n",
    "    ARfile = rootdir + '%s/AR_tagged/Gershunov/SERDP6km_adj/WRF_ARtag_adj.%s.Gershunov.%d.%d.AR%s.nc' % (model, model, year, month, ARtag)\n",
    "\n",
    "    AR_maps = xr.open_dataset(ARfile).AR_tag.values\n",
    "    \n",
    "    return AR_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_full = pd.period_range(start='2003-10-01-00', end='2015-09-30-18', freq='6H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_monthly_stats(year, month):\n",
    "    \n",
    "    # need to use ts_full and ARday_index\n",
    "    \n",
    "    ARtag_HIST = get_AR_maps('HIST', year, month)\n",
    "    ARtag_fSST = get_AR_maps('fSST', year, month)\n",
    "    \n",
    "    ARindex_clip = ARday_index[:, ((ts_full.year==year)*(ts_full.month==month))==1]\n",
    "    nt = ARindex_clip.shape[1]\n",
    "    \n",
    "    sum_HIST1 = np.zeros((450,450)) # common\n",
    "    sum_HIST2 = np.zeros((450,450)) # only HIST\n",
    "    sum_fSST1 = np.zeros((450,450)) # common\n",
    "    sum_fSST2 = np.zeros((450,450)) # only fSST\n",
    "    \n",
    "    for t in np.arange(nt):\n",
    "        if ARindex_clip[0,t]==1 and ARindex_clip[1,t]==1:  # common days\n",
    "            sum_HIST1 = sum_HIST1 + ARtag_HIST[t]\n",
    "            sum_fSST1 = sum_fSST1 + ARtag_fSST[t]\n",
    "        elif ARindex_clip[0,t]==1 and ARindex_clip[1,t]==0: # only HIST\n",
    "            sum_HIST2 = sum_HIST2 + ARtag_HIST[t]\n",
    "        elif ARindex_clip[0,t]==0 and ARindex_clip[1,t]==1: # only fSST\n",
    "            sum_fSST2 = sum_fSST2 + ARtag_fSST[t]\n",
    "        else:\n",
    "            an_index_not_used = 1#print(t, 'not in the case', ARtag_HIST[t].sum(), ARtag_fSST[t].sum())\n",
    "        \n",
    "    return sum_HIST1, sum_HIST2, sum_fSST1, sum_fSST2, nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n"
     ]
    }
   ],
   "source": [
    "frac_HIST1 = np.zeros((144,450,450))\n",
    "frac_HIST2 = np.zeros((144,450,450))\n",
    "frac_fSST1 = np.zeros((144,450,450))\n",
    "frac_fSST2 = np.zeros((144,450,450))\n",
    "\n",
    "count_HIST1 = np.zeros((144,450,450))\n",
    "count_HIST2 = np.zeros((144,450,450))\n",
    "count_fSST1 = np.zeros((144,450,450))\n",
    "count_fSST2 = np.zeros((144,450,450))\n",
    "\n",
    "count = 0\n",
    "year = 2003\n",
    "print(year)\n",
    "for month in np.arange(10,13):\n",
    "    subdata1, subdata2, subdata3, subdata4, nt = compute_monthly_stats(year, month)\n",
    "\n",
    "    frac_HIST1[count] = subdata1/nt\n",
    "    frac_HIST2[count] = subdata2/nt\n",
    "    frac_fSST1[count] = subdata3/nt\n",
    "    frac_fSST2[count] = subdata4/nt\n",
    "    count_HIST1[count] = subdata1\n",
    "    count_HIST2[count] = subdata2\n",
    "    count_fSST1[count] = subdata3\n",
    "    count_fSST2[count] = subdata4\n",
    "    count = count + 1\n",
    "    \n",
    "for year in np.arange(2004,2015):\n",
    "    print(year)\n",
    "    for month in np.arange(1,13):\n",
    "        subdata1, subdata2, subdata3, subdata4, nt = compute_monthly_stats(year, month)\n",
    "\n",
    "        frac_HIST1[count] = subdata1/nt\n",
    "        frac_HIST2[count] = subdata2/nt\n",
    "        frac_fSST1[count] = subdata3/nt\n",
    "        frac_fSST2[count] = subdata4/nt\n",
    "        count_HIST1[count] = subdata1\n",
    "        count_HIST2[count] = subdata2\n",
    "        count_fSST1[count] = subdata3\n",
    "        count_fSST2[count] = subdata4\n",
    "        count = count + 1\n",
    "        \n",
    "year = 2015\n",
    "print(year)\n",
    "for month in np.arange(1,10):\n",
    "    subdata1, subdata2, subdata3, subdata4, nt = compute_monthly_stats(year, month)\n",
    "\n",
    "    frac_HIST1[count] = subdata1/nt\n",
    "    frac_HIST2[count] = subdata2/nt\n",
    "    frac_fSST1[count] = subdata3/nt\n",
    "    frac_fSST2[count] = subdata4/nt\n",
    "    count_HIST1[count] = subdata1\n",
    "    count_HIST2[count] = subdata2\n",
    "    count_fSST1[count] = subdata3\n",
    "    count_fSST2[count] = subdata4\n",
    "    count = count + 1\n",
    "    \n",
    "    \n",
    "tmpfile = '/home/chen423/.tmp/AR-SST/intermediate_data/ARstats.monthly_frac.%s.mat' % version_tag\n",
    "sio.savemat(tmpfile, {'frac_HIST1':frac_HIST1, 'frac_HIST2':frac_HIST2,\n",
    "                      'frac_fSST1':frac_fSST1, 'frac_fSST2':frac_fSST2})\n",
    "\n",
    "tmpfile = '/home/chen423/.tmp/AR-SST/intermediate_data/ARstats.monthly_count.%s.mat' % version_tag\n",
    "sio.savemat(tmpfile, {'count_HIST1':count_HIST1, 'count_HIST2':count_HIST2,\n",
    "                      'count_fSST1':count_fSST1, 'count_fSST2':count_fSST2})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
